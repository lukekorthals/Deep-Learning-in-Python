{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downlaod and Save Resnet 50\n",
    "\n",
    "- To use Resnet50 trained on imagenet as a base for our model, we downloaded it from keras and saved the model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was downloaded and saved already and is not necessary anymore\n",
    "save_resnet_50 = False\n",
    "\n",
    "if save_resnet_50:\n",
    "    resnet_50 = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet')\n",
    "    resnet_50.save(\"./models/resnet50\")\n",
    "    resnet_50.save_weights(\"./models/resnet50/checkpoints/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Data\n",
    "\n",
    "- We used the Animal Image Classification Dataset from Kaggle. \n",
    "- After downloading the dataset, we selected the first 10% of images of each class and moved them to a folder exclusively used for testing. \n",
    "\n",
    "\n",
    "\n",
    "PIYUSHKUMAR.18. (n.d). Animal Image Classification Dataset, Version 1. Retrieved December 6 2022 from https://www.kaggle.com/datasets/piyushkumar18/animal-image-classification-dataset?datasetId=1112806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code moved 10% of the images to a different folder and should not be run again\n",
    "seperate_test_data = False\n",
    "\n",
    "from os import walk, rename\n",
    "path = \"./data/Animal Image Dataset/\"\n",
    "\n",
    "if seperate_test_data:\n",
    "    d = []\n",
    "    for (dirpath, dirnames, filenames) in walk(path):\n",
    "        d.extend(dirnames)\n",
    "        break\n",
    "\n",
    "    for folder in d:\n",
    "        f = []\n",
    "        c_path = f\"{path}{folder}\"\n",
    "        for (dirpath, dirnames, filenames) in walk(c_path):\n",
    "            f.extend(filenames)\n",
    "            break\n",
    "        for ff in f[0:len(f)//10]:\n",
    "            #rename(f\"{path}{folder}/{ff}\", f\"{path}test_data/{folder}/{ff}\") # this moves the files # this is commented out to reduce the risk of running this again \n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Basic Model Template \n",
    "\n",
    "Basic Process\n",
    "- We first trained the most basic model (i.e., resnet + flatten + dense[12]). \n",
    "- Afterwards we developed a more complex model architecture (i.e., resnet + maxpool2d + dropout + dense[24] + dense[12]) and compared its training statistics - train accuracy, train loss, validation accuracy, validation loss - with those from the most basic model.  \n",
    "- The more complex model outperformed the basic model aand we used it as our base for tuning. \n",
    "- During tuning we systematically added additional architectural facets or varied existing hyperparameters, trained the new model, compared it with the previous model and repeated this process with the better performing model. \n",
    "- Because we want to investigate the generalizability of networks we focused on reducing overfit by trying to minimize validation loss. But we also considered accuracy and training time for making the final decision.\n",
    "\n",
    "Detailed Tuning Process\n",
    "- First, we added early stopping to the model. Initially we used a patience of 2 and min delta of .001 because we saw in earlier training cycles without early stopping that validation loss appeared to increase within a short time. \n",
    "- Second, we added an adaptive learning rate to the model. Specifically, we reduce the learning rate by 10% every epoch.  \n",
    "- After adding adaptive learning, we retuned the early stoppping parameters and ended up using a patience of 5 and a min delta of .0001 because together with the adaptive learning rate the model tended to find more optimal solutions after a couple of epochs. \n",
    "- Third, we took out the maxpool2d layer, which we originally included to reduce the number of trainable parameters and thus reduce training time. Taking it out lead to greatly increased performance ata a cost of longer training time. But as training time was still within reason (~10min), we left it in. \n",
    "- Fourth, we took out the first dense layer, which lead to worse performance. Then we reduced the number of units in this layer from 24 to 12, which lead to a big improvement in validation loss. \n",
    "- Fifth, we increased dropout in the first dense layer from 30% to 50%, which further reduced validation loss.\n",
    "- Sixth, added L1 and L2 regularization with standard values to the weigths of the first dense layer, which reduced validation loss slightly. \n",
    "- Seventh, we realized that the gpu was only running at 4% and increased the batch-size used during training from 32 to 320. The gpu was still only using about 6% of its capacity, but this lead to the 16gb RAM maxing out before training could be completed. Nontheless even incomplete training produced very large improvements in validation loss. Thus we reduced the batch size to 250, which is still managable by the 16gb of RAM and lead to very good training accuracy (0.9973), training loss (0.0664), validation accuracy (0.9153) and acceptable validation loss (0.9033) after 24 training epochs taking about 6 minutes. \n",
    "\n",
    "Initial Testing\n",
    "- We tested the performance of this model on the test set and it achieved 90.38% accuracy with a loss of 1.0712.\n",
    "- We concluded that this is satisfactory and decided to use this model architecture for our exploratory study of generizability.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Resnet50 as Base\n",
    "\n",
    "- From now on we load the Resnet50 and its weights from our own folder and not from keras. Resnet serves as the base for our model and is set to non-trainable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "resnet_50 = tf.keras.models.load_model(\"./models/resnet50\")\n",
    "resnet_50.load_weights(\"./models/resnet50/checkpoints/\")\n",
    "resnet_50.trainable = False # freeze layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping and Adaptive Learning\n",
    "\n",
    "We implemented early stopping and adaptive learning as callbacks. Adaptive learning would reduce the learning rate used by the ADAM optimizer by 10% every eopoch starting from the default learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping and adaptive learning are implemented as callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience = 5,\n",
    "    min_delta = .0001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch == 0:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-0.1)\n",
    "adaptive_learning = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Overview of the Model Development\n",
    "\n",
    "- Below you can see the basic model and more complicated model before tuning, and the final model after tuning. \n",
    "- The final version is compiled using the ADAM optimizer with default parameters. We use sparse-categorical-crossentropy to calculate loss according to the softmax classification in the final layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, None, None, 2048)  23587712  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 51200)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 51200)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                614412    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,202,280\n",
      "Trainable params: 614,568\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Basic Model - This was our baseline before the more complicated model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(150, 150, 3)),\n",
    "    resnet_50,\n",
    "    layers.Dense(12, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# More Complicated Model - This was our baseline for tuning\n",
    "model = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(150, 150, 3)),\n",
    "    resnet_50,\n",
    "    layers.MaxPool2D(pool_size=3, strides=1, padding='valid'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(24),\n",
    "    layers.Dense(12, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Final Model - This is the final result after tuning\n",
    "model = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(150, 150, 3)),\n",
    "    resnet_50,\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5), \n",
    "    layers.Dense(12, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)), \n",
    "    layers.Dense(12, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Final Model\n",
    "\n",
    "- We want to use the final model architecture for our future testing and saved it so we can consistently load it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not need to happen again\n",
    "save_model_template = False\n",
    "\n",
    "if save_model_template: \n",
    "    model.save(\"./models/base_model_template\")\n",
    "    model.save(\"./models/base_model_template/checkpoints/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "\n",
    "- We trained six different models on different versions of the dataset (normal, gaussian blur, moption blur, bad exposure, jpg compression, gausian noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# verify gpu is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization and Cache Buffer\n",
    "\n",
    "- EXPLANATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Model\n",
    "\n",
    "- This model was trained on the original dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "- We load the images with a 150x150 size because REASON\n",
    "- As indicated before, we use a batch size of 250 because it is large enough to produce good results, but small enought that the RAM can handle it.\n",
    "- We use 20% of the data for validation. \n",
    "- To improve reproducability we use a seed in the data pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15462 files belonging to 12 classes.\n",
      "Using 12370 files for training.\n",
      "Found 15462 files belonging to 12 classes.\n",
      "Using 3092 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/train/normal_train_data\"\n",
    "image_height = 150\n",
    "image_width = 150\n",
    "batch_size = 250 # RAM can handle this and it leads to good results\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size\n",
    "  )\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size\n",
    "  )\n",
    "\n",
    "# Normalize pixel values between 0 and 255\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(train_ds))\n",
    "\n",
    "# Cach Buffer\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=100,\n",
    "  batch_size=batch_size,\n",
    "  callbacks=[early_stopping, adaptive_learning]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, :].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model = False\n",
    "model_name = \"\"\n",
    "\n",
    "if save_trained_model: \n",
    "    model.save(f\"./models/{model_name}\")\n",
    "    model.save(f\"./models/{model_name}/checkpoints/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Tests On All Models\n",
    "\n",
    "- We tested all models on all versions of the test data (normal, gaussian blur, moption blur, bad exposure, jpg compression, gausian noise)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Test Data Sets\n",
    "\n",
    "- First all test data (normal, gaussian blur, moption blur, bad exposure, jpg compression, gausian noise) sets have to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_sets = {}\n",
    "test_set_dirs = [\"normal_test_data\", \"gblur_test_data\", \"gnoise_test_data\", \"expo_test_data\", \"mblur_test_data\", \"jpgc_test_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tdir in test_set_dirs:\n",
    "    test_data_dir = f\"./data/test/{tdir}\"\n",
    "    all_test_sets[tdir] = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_data_dir,\n",
    "        seed=123,\n",
    "        image_size=(image_height, image_width),\n",
    "        batch_size=batch_size\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests\n",
    "\n",
    "- Each model evaluates each dataset and the results are saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "model_dirs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 11s 278ms/step - loss: 1.1386 - accuracy: 0.9061\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "for mdir in model_dirs:\n",
    "    model_dir = f\"./models/{mdir}\"\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    model.load_weights(f\"{model_dir}/checkpoints/\")\n",
    "\n",
    "    # Run Tests     \n",
    "    test_results[mdir] = {}\n",
    "    for test_set in all_test_sets:\n",
    "        test_results[\"normal_model\"][test_set] = model.evaluate(all_test_sets[test_set])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2817e5a963fe39eff03cb95cdc8f572ee2f2e1817bf2ac4532382cdfef8588ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
