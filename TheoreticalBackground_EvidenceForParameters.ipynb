{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6abdd0",
   "metadata": {},
   "source": [
    "# Deep Learning Theoretical Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b8167",
   "metadata": {},
   "source": [
    "### General Background for citation\n",
    "\n",
    "Roy et al. (2018) uses 6 common CNN(MobileNet, VGG16, VGG19, ResNet50, InceptionV3 along with CapsuleNet) with various levels of image degradation to test image classification (https://arxiv.org/abs/1807.10108). Their methods of image degradation were (a) Gaussian white noise, (b) Colored Gaussian noise, (c) salt and pepper noise, (d) motion blur, (e) Gaussian blur, (f) Degradation due to JPEG compression (JPEG quality).\n",
    "The note that shallower image classification models (e.g. VGG) are more resilient to image degradation, i.e. that depth decreases robustness. \n",
    "No relevant future research (adversarial attacks being different). \n",
    "\n",
    "Rekha et al. (2020) used CNN to identify aquatic animals with images “fluctuating degrees of luminous intensity and opacity“. (https://www.researchgate.net/profile/Rekha-B-S/publication/338418046_Fish_Detection_and_Classification_Using_Convolutional_Neural_Networks/links/5efc1b1c458515505080fcbd/Fish-Detection-and-Classification-Using-Convolutional-Neural-Networks.pdf?origin=publication_detail)\n",
    "They use a region-proposal-based CNN called Fast R-CNN to first find an item of question and then use a classifier, with a VGG-16 base. They mention a limitation of time, stating that image detection took around 5s, with classification being near instantaneously. \n",
    "\n",
    "(https://arxiv.org/pdf/1604.04004.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d8ccc",
   "metadata": {},
   "source": [
    "Find paper for image classification size of input\n",
    "Using seeds? \n",
    "\n",
    "Framework called LIME (interpret networks)\n",
    "Takes images, changes things on the image to see where things go wrong\n",
    "\n",
    "https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f57f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feynman AI\n",
    "\n",
    "https://www.researchgate.net/publication/326430739_A_Low-Light_Image_Enhancement_Method_Based_on_Image_Degradation_Model_and_Pure_Pixel_Ratio_Prior\n",
    "\n",
    "https://www.kaggle.com/code/basu369victor/low-light-image-enhancement-with-cnn\n",
    "Uses batch_size of 32\n",
    "\n",
    "Motion Blur (vertical, horizontal)\n",
    "Light Noise (ISO, low-light)\n",
    "Underexposed\n",
    "Overexposed\n",
    "JPEG\n",
    "Poor focus (gaussian blur?)\n",
    "\n",
    "Find Examples for hyper-parameter\n",
    "Reasoning for decisions (motion blur)\n",
    "\n",
    "https://stackoverflow.com/questions/14626880/simulation-of-unfocused-image \n",
    "Their solution to mimic unfocused picture: Point-Spread Function\n",
    "\n",
    "http://www2.ujf-grenoble.fr/medecine/iab/clientzone/plforme9/fichiers/DeconvolutionMicroscopy_Sibarita_Springer.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
